{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据规模： 5000  *  23\n",
      "删除GPS属性后，数据规模： 5000  *  21\n",
      "初始特征数目： 20\n",
      "特征合并后，特征数目变为： 16\n",
      "特征提取后，特征数目： 64\n",
      "\n",
      "各成分占总方差比例：\n",
      "[9.45828907e-01 3.07379595e-02 1.13674355e-02 8.19292080e-03\n",
      " 2.88258934e-03 4.61514085e-04 2.57997684e-04 2.01222208e-04\n",
      " 4.48335067e-05 9.59434216e-06 8.32720191e-06 3.02405381e-06\n",
      " 1.57778332e-06 5.70377198e-07 4.96711492e-07 3.04100514e-07\n",
      " 2.11480545e-07 1.43320650e-07 5.82599240e-08 4.02988461e-08\n",
      " 3.98086831e-08 3.26740449e-08 2.69924047e-08 2.54574525e-08\n",
      " 1.70071564e-08 1.57250251e-08 1.42831479e-08 1.18586735e-08\n",
      " 1.09377613e-08 1.03503509e-08 8.44877676e-09 5.91084830e-09\n",
      " 5.56055968e-09 5.19403353e-09 4.62302373e-09 4.37079234e-09\n",
      " 3.68732705e-09 3.47966538e-09 3.06563732e-09 2.94213067e-09\n",
      " 2.81094115e-09 2.40516505e-09 1.93931885e-09 1.52553479e-09\n",
      " 1.43412350e-09 1.16279839e-09 1.12319208e-09 9.38585249e-10\n",
      " 7.88811659e-10 7.60132379e-10 6.33618788e-10 5.52678919e-10\n",
      " 4.88932199e-10 4.69217707e-10 4.29464928e-10 3.96559326e-10\n",
      " 3.68948410e-10 3.55140066e-10 2.59073349e-10 2.43516124e-10\n",
      " 2.25546638e-10 1.97294465e-10 1.57549379e-10 1.41718101e-10\n",
      " 7.41102955e-11 5.92565310e-11 5.31756749e-11 4.83203503e-11\n",
      " 4.18287596e-11 3.96836164e-11 2.67332806e-11 2.22790070e-11\n",
      " 1.44230167e-11 1.23421594e-11 1.09382211e-11 9.42226247e-12\n",
      " 6.17349349e-12 3.78080197e-12 1.30138390e-12]\n",
      "各成分方差：\n",
      "[5.66355411e+08 1.84056647e+07 6.80673701e+06 4.90586087e+06\n",
      " 1.72607335e+06 2.76351249e+05 1.54487121e+05 1.20490382e+05\n",
      " 2.68459749e+04 5.74502170e+03 4.98626741e+03 1.81078124e+03\n",
      " 9.44765076e+02 3.41537682e+02 2.97427198e+02 1.82093157e+02\n",
      " 1.26632999e+02 8.58193538e+01 3.48856151e+01 2.41306534e+01\n",
      " 2.38371474e+01 1.95649784e+01 1.61628539e+01 1.52437358e+01\n",
      " 1.01837605e+01 9.41602968e+00 8.55264419e+00 7.10088667e+00\n",
      " 6.54945124e+00 6.19771420e+00 5.05906554e+00 3.53937260e+00\n",
      " 3.32962235e+00 3.11014917e+00 2.76823269e+00 2.61719839e+00\n",
      " 2.20794438e+00 2.08359810e+00 1.83568114e+00 1.76172626e+00\n",
      " 1.68317094e+00 1.44019518e+00 1.16124990e+00 9.13479038e-01\n",
      " 8.58742634e-01 6.96275148e-01 6.72559176e-01 5.62017962e-01\n",
      " 4.72334635e-01 4.55161692e-01 3.79406282e-01 3.30940082e-01\n",
      " 2.92769014e-01 2.80964121e-01 2.57160448e-01 2.37456815e-01\n",
      " 2.20923601e-01 2.12655266e-01 1.55131221e-01 1.45815669e-01\n",
      " 1.35055672e-01 1.18138478e-01 9.43394126e-02 8.48597595e-02\n",
      " 4.43767013e-02 3.54823761e-02 3.18412040e-02 2.89338713e-02\n",
      " 2.50467544e-02 2.37622584e-02 1.60076923e-02 1.33405060e-02\n",
      " 8.63639658e-03 7.39039453e-03 6.54972653e-03 5.64198164e-03\n",
      " 3.69664261e-03 2.26391648e-03 7.79259130e-04]\n",
      "最后十个数据为：\n",
      "        avg_1     max_1     min_1     std_1     avg_2     max_2     min_2  \\\n",
      "265  0.053276  0.048753  0.322551  0.028014  0.071513  0.103117  0.213896   \n",
      "294  0.050268  0.045216  0.325980  0.022045  0.093635  0.098712  0.263232   \n",
      "93   0.039906  0.040224  0.299773  0.026325  0.037645  0.062903  0.138509   \n",
      "239  0.046191  0.034343  0.321700  0.011467  0.058744  0.060235  0.213817   \n",
      "380  0.755322  0.834896  0.718520  0.630766  0.595110  0.989157  0.372227   \n",
      "359  0.883303  0.952678  0.911085  0.758188  0.522456  0.966216  0.236021   \n",
      "0    0.000000  0.000000  0.260207  0.003868  0.061617  0.053061  0.254436   \n",
      "363  0.673161  0.991675  0.381705  0.790555  0.587747  0.843936  0.400487   \n",
      "20   0.028056  0.017221  0.311479  0.000452  0.074246  0.058301  0.296134   \n",
      "333  0.686934  0.969285  0.462673  0.856051  0.718725  0.995706  0.758325   \n",
      "\n",
      "        std_2     avg_3     max_3    ...       min_18    std_18    avg_21  \\\n",
      "265  0.069798  0.609063  0.635872    ...     0.335198  0.479961  0.445743   \n",
      "294  0.049618  0.588227  0.580174    ...     0.286323  0.394943  0.484576   \n",
      "93   0.051930  0.776656  0.964599    ...     0.007329  0.801333  0.686233   \n",
      "239  0.032836  0.696507  0.617901    ...     0.425130  0.511515  0.605958   \n",
      "380  0.840292  0.661246  0.670468    ...     0.353719  0.576388  0.428806   \n",
      "359  0.784948  0.525579  0.577118    ...     0.286355  0.384753  0.405277   \n",
      "0    0.008007  0.504157  0.410345    ...     0.529586  0.075397  0.008677   \n",
      "363  0.686495  0.544954  0.564258    ...     0.343451  0.532743  0.410474   \n",
      "20   0.001200  0.512703  0.390388    ...     0.587688  0.031917  0.000073   \n",
      "333  0.678165  0.727147  0.646944    ...     0.317814  0.500534  0.374621   \n",
      "\n",
      "       max_21    min_21    std_21    avg_22    max_22    min_22    std_22  \n",
      "265  0.612860  0.287503  0.235382  0.000738  0.000813  0.000061  0.000547  \n",
      "294  0.629802  0.265400  0.250547  0.000424  0.000831  0.000109  0.000518  \n",
      "93   0.877168  0.393161  0.312886  0.640930  0.957611  0.286114  0.810427  \n",
      "239  0.637971  0.571231  0.049701  0.000063  0.000081  0.000004  0.000076  \n",
      "380  0.630225  0.243744  0.230375  0.000728  0.000791  0.000016  0.000631  \n",
      "359  0.629578  0.217560  0.279899  0.000611  0.000818  0.000113  0.000760  \n",
      "0    0.008859  0.008307  0.000563  0.000716  0.005001  0.000000  0.003912  \n",
      "363  0.623041  0.217971  0.269720  0.000596  0.000759  0.000232  0.000617  \n",
      "20   0.000030  0.000103  0.000000  0.005776  0.004168  0.008521  0.000000  \n",
      "333  0.613176  0.227734  0.258177  0.000533  0.000722  0.000035  0.000749  \n",
      "\n",
      "[10 rows x 80 columns]\n",
      "kNN算法预测准确率为： 0.65\n",
      "最后10个数据预测标签\n",
      "['Angry' 'Angry' 'Depressed' 'Happy' 'Happy' 'Happy' 'Angry' 'Happy'\n",
      " 'Angry' 'Angry']\n",
      "最后10个数据真实标签\n",
      "265        Angry\n",
      "294        Angry\n",
      "93     Depressed\n",
      "239        Angry\n",
      "380        Angry\n",
      "359        Angry\n",
      "0          Fight\n",
      "363        Angry\n",
      "20         Angry\n",
      "333        Happy\n",
      "Name: labels, dtype: object\n",
      "耗时0.000s\n",
      "\n",
      "SVC算法(kernel='linear')预测准确率为： 0.65\n",
      "最后10个数据预测标签\n",
      "['Angry' 'Angry' 'Depressed' 'Happy' 'Angry' 'Happy' 'Fight' 'Happy'\n",
      " 'Angry' 'Angry']\n",
      "最后10个数据真实标签\n",
      "265        Angry\n",
      "294        Angry\n",
      "93     Depressed\n",
      "239        Angry\n",
      "380        Angry\n",
      "359        Angry\n",
      "0          Fight\n",
      "363        Angry\n",
      "20         Angry\n",
      "333        Happy\n",
      "Name: labels, dtype: object\n",
      "耗时0.012s\n",
      "\n",
      "SVC算法(kernel='poly')预测准确率为： 0.66\n",
      "最后10个数据预测标签\n",
      "['Angry' 'Angry' 'Depressed' 'Angry' 'Angry' 'Angry' 'Angry' 'Angry'\n",
      " 'Angry' 'Angry']\n",
      "最后10个数据真实标签\n",
      "265        Angry\n",
      "294        Angry\n",
      "93     Depressed\n",
      "239        Angry\n",
      "380        Angry\n",
      "359        Angry\n",
      "0          Fight\n",
      "363        Angry\n",
      "20         Angry\n",
      "333        Happy\n",
      "Name: labels, dtype: object\n",
      "耗时0.024s\n",
      "\n",
      "SVC算法(kernel='rbf')预测准确率为： 0.74\n",
      "最后10个数据预测标签\n",
      "['Angry' 'Angry' 'Depressed' 'Angry' 'Angry' 'Angry' 'Angry' 'Angry'\n",
      " 'Angry' 'Angry']\n",
      "最后10个数据真实标签\n",
      "265        Angry\n",
      "294        Angry\n",
      "93     Depressed\n",
      "239        Angry\n",
      "380        Angry\n",
      "359        Angry\n",
      "0          Fight\n",
      "363        Angry\n",
      "20         Angry\n",
      "333        Happy\n",
      "Name: labels, dtype: object\n",
      "耗时0.020s\n",
      "\n",
      "高斯朴素贝叶斯算法预测准确率为： 0.57\n",
      "最后10个数据预测标签\n",
      "['Fight' 'Angry' 'Depressed' 'Fight' 'Angry' 'Angry' 'Fight' 'Angry'\n",
      " 'Angry' 'Angry']\n",
      "最后10个数据真实标签\n",
      "265        Angry\n",
      "294        Angry\n",
      "93     Depressed\n",
      "239        Angry\n",
      "380        Angry\n",
      "359        Angry\n",
      "0          Fight\n",
      "363        Angry\n",
      "20         Angry\n",
      "333        Happy\n",
      "Name: labels, dtype: object\n",
      "耗时0.000s\n",
      "\n",
      "多项式分布朴素贝叶斯算法预测准确率为： 0.74\n",
      "最后10个数据预测标签\n",
      "['Angry' 'Angry' 'Depressed' 'Angry' 'Angry' 'Angry' 'Angry' 'Angry'\n",
      " 'Angry' 'Angry']\n",
      "最后10个数据真实标签\n",
      "265        Angry\n",
      "294        Angry\n",
      "93     Depressed\n",
      "239        Angry\n",
      "380        Angry\n",
      "359        Angry\n",
      "0          Fight\n",
      "363        Angry\n",
      "20         Angry\n",
      "333        Happy\n",
      "Name: labels, dtype: object\n",
      "耗时0.000s\n",
      "\n",
      "伯努利分布贝叶斯算法预测准确率为： 0.33\n",
      "最后10个数据预测标签\n",
      "['Happy' 'Happy' 'Happy' 'Happy' 'Happy' 'Happy' 'Fight' 'Happy' 'Fight'\n",
      " 'Happy']\n",
      "最后10个数据真实标签\n",
      "265        Angry\n",
      "294        Angry\n",
      "93     Depressed\n",
      "239        Angry\n",
      "380        Angry\n",
      "359        Angry\n",
      "0          Fight\n",
      "363        Angry\n",
      "20         Angry\n",
      "333        Happy\n",
      "Name: labels, dtype: object\n",
      "耗时0.000s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest,chi2 \n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "def importData():\n",
    "    data1 = pd.read_table('data1.txt', sep=',')\n",
    "    data2 = pd.read_table('data2.txt', sep=',')\n",
    "    # 数据收集完成后，发现GPS经纬度基本没有变化（大小变化约在8位以后），所以删除经纬度，\n",
    "    # 因收集样本有限，并且大部分人都在室内活动，情景模式基本都为震动，没有太大参考价值，删除情景模式\n",
    "    data1 = data1.drop('19', 1)\n",
    "    data1 = data1.drop('20', 1)\n",
    "    data1 = data1.drop('23', 1)\n",
    "    allData = data1.append(data2)\n",
    "    return allData\n",
    "\n",
    "\n",
    "def newFeaturesAndLabelsInit():\n",
    "    newFeatures = pd.DataFrame(\n",
    "        columns=['avg_1', 'max_1', 'min_1', 'std_1', 'avg_2', 'max_2', 'min_2', 'std_2', 'avg_3', 'max_3', 'min_3',\n",
    "                 'std_3',\n",
    "                 'avg_4', 'max_4', 'min_4', 'std_4', 'avg_5', 'max_5', 'min_5', 'std_5', 'avg_6', 'max_6', 'min_6',\n",
    "                 'std_6',\n",
    "                 'avg_7', 'max_7', 'min_7', 'std_7', 'avg_8', 'max_8', 'min_8', 'std_8', 'avg_9', 'max_9', 'min_9',\n",
    "                 'std_9',\n",
    "                 'avg_10', 'max_10', 'min_10', 'std_10', 'avg_11', 'max_11', 'min_11', 'std_11',\n",
    "                 'avg_12', 'max_12', 'min_12', 'std_12', 'avg_13', 'max_13', 'min_13', 'std_13',\n",
    "                 'avg_14', 'max_14', 'min_14', 'std_14', 'avg_15', 'max_15', 'min_15', 'std_15',\n",
    "                 'avg_16', 'max_16', 'min_16', 'std_16', 'avg_17', 'max_17', 'min_17', 'std_17',\n",
    "                 'avg_18', 'max_18', 'min_18', 'std_18', 'avg_21', 'max_21', 'min_21', 'std_21',\n",
    "                 'avg_22', 'max_22', 'min_22', 'std_22'])\n",
    "    newLabels = pd.DataFrame(columns=['labels'])\n",
    "    return newFeatures, newLabels\n",
    "\n",
    "\n",
    "def handleData(length, count):\n",
    "    list_avg = []\n",
    "    list_max = []\n",
    "    list_min = []\n",
    "    list_std = []\n",
    "    list_labels = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < (length - 10):\n",
    "        j = i + 10\n",
    "        data_slice = features.iloc[i:j, count]  # iloc函数传入的参数是位置索引\n",
    "        list_avg.append(data_slice.mean())\n",
    "        list_max.append(data_slice.max())\n",
    "        list_min.append(data_slice.min())\n",
    "        list_std.append(data_slice.std())\n",
    "        i = j\n",
    "    newFeatures['avg_' + str(count + 1)] = np.array(list_avg)\n",
    "    newFeatures['max_' + str(count + 1)] = np.array(list_max)\n",
    "    newFeatures['min_' + str(count + 1)] = np.array(list_min)\n",
    "    newFeatures['std_' + str(count + 1)] = np.array(list_std)\n",
    "    list_avg.clear()\n",
    "    list_max.clear()\n",
    "    list_min.clear()\n",
    "    list_std.clear()\n",
    "\n",
    "\n",
    "def handleData2():\n",
    "    list_avg = []\n",
    "    list_max = []\n",
    "    list_min = []\n",
    "    list_std = []\n",
    "    list_labels = []\n",
    "\n",
    "    handleData(features.shape[0], 0)\n",
    "    handleData(features.shape[0], 1)\n",
    "    handleData(features.shape[0], 2)\n",
    "    handleData(features.shape[0], 3)\n",
    "    handleData(features.shape[0], 4)\n",
    "    handleData(features.shape[0], 5)\n",
    "    handleData(features.shape[0], 6)\n",
    "    handleData(features.shape[0], 7)\n",
    "    handleData(features.shape[0], 8)\n",
    "    handleData(features.shape[0], 9)\n",
    "    handleData(features.shape[0], 10)\n",
    "    handleData(features.shape[0], 11)\n",
    "    handleData(features.shape[0], 12)\n",
    "    handleData(features.shape[0], 13)\n",
    "    handleData(features.shape[0], 14)\n",
    "    handleData(features.shape[0], 15)\n",
    "    handleData(features.shape[0], 16)\n",
    "    handleData(features.shape[0], 17)\n",
    "    # for count in range(17):\n",
    "    #     handleData(features.shape[0],count)\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < (features.shape[0] - 10):\n",
    "        j = i + 10\n",
    "        data_slice = features.iloc[i:j, 18]\n",
    "        list_avg.append(data_slice.mean())\n",
    "        list_max.append(data_slice.max())\n",
    "        list_min.append(data_slice.min())\n",
    "        list_std.append(data_slice.std())\n",
    "        i = j\n",
    "    newFeatures['avg_21'] = np.array(list_avg)\n",
    "    newFeatures['max_21'] = np.array(list_max)\n",
    "    newFeatures['min_21'] = np.array(list_min)\n",
    "    newFeatures['std_21'] = np.array(list_std)\n",
    "    list_avg.clear()\n",
    "    list_max.clear()\n",
    "    list_min.clear()\n",
    "    list_std.clear()\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < (features.shape[0] - 10):\n",
    "        j = i + 10\n",
    "        data_slice = features.iloc[i:j, 19]\n",
    "        list_avg.append(data_slice.mean())\n",
    "        list_max.append(data_slice.max())\n",
    "        list_min.append(data_slice.min())\n",
    "        list_std.append(data_slice.std())\n",
    "        list_labels.append(allData.iloc[i, -1])  # 选取allData里面第i行，最后一列作为labels\n",
    "        i = j\n",
    "    newFeatures['avg_22'] = np.array(list_avg)\n",
    "    newFeatures['max_22'] = np.array(list_max)\n",
    "    newFeatures['min_22'] = np.array(list_min)\n",
    "    newFeatures['std_22'] = np.array(list_std)\n",
    "    newLabels['labels'] = np.array(list_labels)\n",
    "    list_avg.clear()\n",
    "    list_max.clear()\n",
    "    list_min.clear()\n",
    "    list_std.clear()\n",
    "    list_labels.clear()\n",
    "    return newFeatures, newLabels\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 数据导入\n",
    "    allData = importData()\n",
    "\n",
    "    # 数据预处理\n",
    "    # 清理整行属性都为空的行\n",
    "    allData.dropna(how=\"all\")\n",
    "    # 本来打算填充众数，因为无缺失值，后改为删除含有空属性的行，结果不变\n",
    "    allData.dropna(axis=0)\n",
    "    # 剩余部分缺失值也可以采用出现最频繁的值填充\n",
    "    # freq_port = allData.Embarked.dropna().mode()[0] # mode返回出现最多的数据，可能出现多个，因此返回数组,取第0个\n",
    "    # dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n",
    "\n",
    "    # 输出数据形状\n",
    "    allData_row = allData.shape[0]\n",
    "    allDate_col = allData.shape[1]\n",
    "    print(\"原始数据规模：\", allData.shape[0], \" * \", allData.shape[1]+2)\n",
    "    print(\"删除GPS属性后，数据规模：\", allData.shape[0], \" * \", allData.shape[1])\n",
    "\n",
    "    # 选取所有行，和最后一列之前的所有列，后面的“：-1”表示左闭右开\n",
    "    features = allData.iloc[:, :-1]\n",
    "    print(\"初始特征数目：\", features.shape[1])\n",
    "    new_features_shape = features.shape[1]-4\n",
    "    print(\"特征合并后，特征数目变为：\",new_features_shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # 特征提取\n",
    "    # 以每10组数据为一组提取获得的20个属性的平均值，最大值，最小值，标准差，作为新的特征向量\n",
    "    newFeatures, newLabels = newFeaturesAndLabelsInit()\n",
    "    newFeatures, newLabels = handleData2()\n",
    "\n",
    "    # 输出提取特征后，新的特征维度个数\n",
    "    newFeatures_row = newFeatures.shape[1]-16\n",
    "    print(\"特征提取后，特征数目：\", newFeatures_row)\n",
    "    print()\n",
    "    \n",
    "    # PCA降维过程\n",
    "    pca = PCA(n_components = 'mle',copy = False).fit(newFeatures)\n",
    "    # 输出降维后的结果\n",
    "#     print(X_train_pca.shape)\n",
    "    print(\"各成分占总方差比例：\")\n",
    "    print(pca.explained_variance_ratio_ )\n",
    "    print(\"各成分方差：\")\n",
    "    print(pca.explained_variance_ )\n",
    "    \n",
    "    # 归一化处理\n",
    "    normal_data = (newFeatures - newFeatures.min()) / (newFeatures.max() - newFeatures.min())\n",
    "    \n",
    "\n",
    "\n",
    "    # 特征和标签分别赋值\n",
    "    X = normal_data\n",
    "    y = newLabels['labels']\n",
    "    # 划分训练集和预测集\n",
    "    # 设置stratify = y时，我们发现每次划分后，测试集和训练集中的类标签比例同原始的样本中类标签的比例相同\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "    \n",
    "\n",
    "    # 进行预测\n",
    "    print(\"最后十个数据为：\")\n",
    "    print(X_test.tail(10))\n",
    "    # kNN\n",
    "    t0 = time.time()\n",
    "    clf = KNeighborsClassifier(n_neighbors=16, algorithm='auto', weights='distance')\n",
    "    clf.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    print(\"kNN算法预测准确率为：\", clf.score(X_test, y_test))\n",
    "    print(\"最后10个数据预测标签\")\n",
    "    labelPredict = clf.predict(X_test.tail(10))\n",
    "    print(labelPredict)\n",
    "    print(\"最后10个数据真实标签\")\n",
    "    labelData = y_test.tail(10)\n",
    "    print(labelData)\n",
    "    print(\"耗时%0.3fs\\n\" % (t1 - t0))\n",
    "#     # 绘制图像显示不同K值对应的预测准确率\n",
    "#     k_range = range(1, 31)\n",
    "#     k_scores = []\n",
    "#     for k in k_range:\n",
    "#         clf = KNeighborsClassifier(n_neighbors=k)\n",
    "#         # loss = -cross_val_score(clf, X, y, cv=10, scoring='mean_squared_error') # for regression\n",
    "#         # 当cv参数是一个整型时，cross_val_score默认使用KFold 或StratifiedKFold的方法进行数据集打乱\n",
    "#         scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')  # for classification\n",
    "#         k_scores.append(scores.mean())\n",
    "#     plt.plot(k_range, k_scores)\n",
    "#     plt.xlabel('Value of K for KNN')\n",
    "#     plt.ylabel('Cross-Validated Accuracy')\n",
    "#     plt.show()\n",
    "\n",
    "    # SVC(kernel='linear')\n",
    "    t0 = time.time()\n",
    "    clf = svm.SVC(kernel='linear',decision_function_shape='ovo')\n",
    "    clf.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    print(\"SVC算法(kernel='linear')预测准确率为：\", clf.score(X_test, y_test))\n",
    "    print(\"最后10个数据预测标签\")\n",
    "    labelPredict = clf.predict(X_test.tail(10))\n",
    "    print(labelPredict)\n",
    "    print(\"最后10个数据真实标签\")\n",
    "    labelData = y_test.tail(10)\n",
    "    print(labelData)\n",
    "    print(\"耗时%0.3fs\\n\" % (t1 - t0))\n",
    "\n",
    "    # SVC(kernel='poly')\n",
    "    t0 = time.time()\n",
    "    clf = svm.SVC(kernel='poly',decision_function_shape='ovo')\n",
    "    clf.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    print(\"SVC算法(kernel='poly')预测准确率为：\", clf.score(X_test, y_test))\n",
    "    print(\"最后10个数据预测标签\")\n",
    "    labelPredict = clf.predict(X_test.tail(10))\n",
    "    print(labelPredict)\n",
    "    print(\"最后10个数据真实标签\")\n",
    "    labelData = y_test.tail(10)\n",
    "    print(labelData)\n",
    "    print(\"耗时%0.3fs\\n\" % (t1 - t0))\n",
    "\n",
    "    # SVC(kernel='rbf')\n",
    "    t0 = time.time()\n",
    "    clf = svm.SVC(kernel='rbf',decision_function_shape='ovo')\n",
    "    clf.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    print(\"SVC算法(kernel='rbf')预测准确率为：\", clf.score(X_test, y_test))\n",
    "    print(\"最后10个数据预测标签\")\n",
    "    labelPredict = clf.predict(X_test.tail(10))\n",
    "    print(labelPredict)\n",
    "    print(\"最后10个数据真实标签\")\n",
    "    labelData = y_test.tail(10)\n",
    "    print(labelData)\n",
    "    print(\"耗时%0.3fs\\n\" % (t1 - t0))\n",
    "\n",
    "    # 高斯朴素贝叶斯\n",
    "    t0 = time.time()\n",
    "    clf = GaussianNB().fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    print(\"高斯朴素贝叶斯算法预测准确率为：\", clf.score(X_test, y_test))\n",
    "    print(\"最后10个数据预测标签\")\n",
    "    labelPredict = clf.predict(X_test.tail(10))\n",
    "    print(labelPredict)\n",
    "    print(\"最后10个数据真实标签\")\n",
    "    labelData = y_test.tail(10)\n",
    "    print(labelData)\n",
    "    print(\"耗时%0.3fs\\n\" % (t1 - t0))\n",
    "\n",
    "    # 多项式分布\n",
    "    t0 = time.time()\n",
    "    clf = MultinomialNB().fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    print(\"多项式分布朴素贝叶斯算法预测准确率为：\", clf.score(X_test, y_test))\n",
    "    print(\"最后10个数据预测标签\")\n",
    "    labelPredict = clf.predict(X_test.tail(10))\n",
    "    print(labelPredict)\n",
    "    print(\"最后10个数据真实标签\")\n",
    "    labelData = y_test.tail(10)\n",
    "    print(labelData)\n",
    "    print(\"耗时%0.3fs\\n\" % (t1 - t0))\n",
    "\n",
    "    # 伯努利分布\n",
    "    t0 = time.time()\n",
    "    clf = BernoulliNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    print(\"伯努利分布贝叶斯算法预测准确率为：\", clf.score(X_test, y_test))\n",
    "    print(\"最后10个数据预测标签\")\n",
    "    labelPredict = clf.predict(X_test.tail(10))\n",
    "    print(labelPredict)\n",
    "    print(\"最后10个数据真实标签\")\n",
    "    labelData = y_test.tail(10)\n",
    "    print(labelData)\n",
    "    print(\"耗时%0.3fs\\n\" % (t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits  \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.model_selection import GridSearchCV  \n",
    "from sklearn.metrics import classification_report  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn import metrics  \n",
    "  \n",
    "data=load_digits()  \n",
    "x=data.data  \n",
    "y=data.target  \n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0,test_size=0.25,  \n",
    "                                              stratify=y)  \n",
    "#采用暴力搜索，所有参数进行组合，然后选择最好的参数  \n",
    "tuned_parameters=[{'penalty':['l1','l2'],  \n",
    "                   'C':[0.01,0.05,0.1,0.5,1,5,10,50,100],  \n",
    "                    'solver':['liblinear'],  \n",
    "                    'multi_class':['ovr']},  \n",
    "                {'penalty':['l2'],  \n",
    "                 'C':[0.01,0.05,0.1,0.5,1,5,10,50,100],  \n",
    "                'solver':['lbfgs'],  \n",
    "                'multi_class':['ovr','multinomial']}]  \n",
    "  \n",
    "clf=GridSearchCV(LogisticRegression(tol=1e-6),tuned_parameters,cv=10)  \n",
    "clf.fit(x_train,y_train)  \n",
    "print('Best parameters set found:',clf.best_params_)  \n",
    "  \n",
    "print(classification_report(y_test,clf.predict(x_test)))  \n",
    "print(metrics.confusion_matrix(y_test,clf.predict(x_test)))  \n",
    "  \n",
    "  \n",
    "from sklearn.datasets import load_digits  \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.model_selection import RandomizedSearchCV  \n",
    "from sklearn.metrics import classification_report  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "import scipy  \n",
    "  \n",
    "digits=load_digits()  \n",
    "x=digits.data  \n",
    "y=digits.target  \n",
    "  \n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0,test_size=0.25,  \n",
    "                                               stratify=y)  \n",
    "#采用随机搜索，给参数一个范围，然后系统随机选择参数，进行检验，然后选择最好的  \n",
    "tuned_parameters={'C':scipy.stats.expon(scale=100),  \n",
    "                  'multi_class':['ovr','multinomial']}  \n",
    "clf=RandomizedSearchCV(LogisticRegression(penalty='l2',solver='lbfgs',tol=1e-6),  \n",
    "                   tuned_parameters,cv=10,scoring='accuracy',n_iter=100)  \n",
    "  \n",
    "clf.fit(x_train,y_train)  \n",
    "print('best parameters:',clf.best_estimator_)  \n",
    "print(classification_report(y_test,clf.predict(x_test)))  \n",
    "print(metrics.confusion_matrix(y_test,clf.predict(x_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据规模： 5000  *  23\n",
      "删除GPS属性后，数据规模： 5000  *  21\n",
      "特征数目： 20\n",
      "特征提取后，特征数目： 80\n",
      "\n",
      "(499, 77)\n",
      "各成分占总方差比例：\n",
      "[4.77235500e-01 2.44377697e-01 9.64084507e-02 7.79858610e-02\n",
      " 2.51147925e-02 1.23279045e-02 6.72806670e-03 5.65828423e-03\n",
      " 4.61270546e-03 3.90539460e-03 3.41311893e-03 2.90614904e-03\n",
      " 2.67626673e-03 2.26970945e-03 2.24993191e-03 2.17407565e-03\n",
      " 2.06693256e-03 1.88239100e-03 1.70663766e-03 1.56358548e-03\n",
      " 1.53763311e-03 1.46027649e-03 1.36201868e-03 1.29214190e-03\n",
      " 1.16932783e-03 1.15016981e-03 1.04310998e-03 1.00112181e-03\n",
      " 9.75298101e-04 8.28505870e-04 7.89400771e-04 6.95176181e-04\n",
      " 6.91725927e-04 6.38010389e-04 5.70157716e-04 5.13189093e-04\n",
      " 5.02685650e-04 4.74307632e-04 4.29719367e-04 4.11470978e-04\n",
      " 3.74127660e-04 3.66120324e-04 3.39772507e-04 2.87457740e-04\n",
      " 2.77400910e-04 2.42290522e-04 2.26001747e-04 2.12502650e-04\n",
      " 1.98345680e-04 1.92969765e-04 1.72532390e-04 1.53704155e-04\n",
      " 1.53557918e-04 1.46719494e-04 1.42934813e-04 1.30338066e-04\n",
      " 1.29993536e-04 1.20794777e-04 1.19918920e-04 1.00633143e-04\n",
      " 9.33529040e-05 9.07812535e-05 8.83499288e-05 8.58245350e-05\n",
      " 8.28817946e-05 7.50003783e-05 7.24112359e-05 6.32461398e-05\n",
      " 6.00080574e-05 5.67862597e-05 5.21220950e-05 4.75054980e-05\n",
      " 4.51943512e-05 4.18663643e-05 3.75852551e-05 3.12492187e-05\n",
      " 3.00213740e-05]\n",
      "各成分方差：\n",
      "[2.33104885e+00 1.19365879e+00 4.70905470e-01 3.80920638e-01\n",
      " 1.22672785e-01 6.02154439e-02 3.28631296e-02 2.76377950e-02\n",
      " 2.25306829e-02 1.90758348e-02 1.66713225e-02 1.41950365e-02\n",
      " 1.30721802e-02 1.10863580e-02 1.09897549e-02 1.06192362e-02\n",
      " 1.00958976e-02 9.19450747e-03 8.33604321e-03 7.63730723e-03\n",
      " 7.51054330e-03 7.13269615e-03 6.65275755e-03 6.31144557e-03\n",
      " 5.71156230e-03 5.61798528e-03 5.09505332e-03 4.88996277e-03\n",
      " 4.76382731e-03 4.04682311e-03 3.85581491e-03 3.39557646e-03\n",
      " 3.37872376e-03 3.11635111e-03 2.78492586e-03 2.50666357e-03\n",
      " 2.45535968e-03 2.31674772e-03 2.09895708e-03 2.00982313e-03\n",
      " 1.82742032e-03 1.78830862e-03 1.65961315e-03 1.40408254e-03\n",
      " 1.35496012e-03 1.18346402e-03 1.10390177e-03 1.03796565e-03\n",
      " 9.68816168e-04 9.42557602e-04 8.42731584e-04 7.50765385e-04\n",
      " 7.50051092e-04 7.16648923e-04 6.98162709e-04 6.36634110e-04\n",
      " 6.34951260e-04 5.90020076e-04 5.85741966e-04 4.91540911e-04\n",
      " 4.55980703e-04 4.43419519e-04 4.31543754e-04 4.19208510e-04\n",
      " 4.04834744e-04 3.66338097e-04 3.53691475e-04 3.08924716e-04\n",
      " 2.93108356e-04 2.77371539e-04 2.54589504e-04 2.32039813e-04\n",
      " 2.20751055e-04 2.04495558e-04 1.83584552e-04 1.52636288e-04\n",
      " 1.46638901e-04]\n",
      "最后十个数据为：\n",
      "        avg_1     max_1     min_1     std_1     avg_2     max_2     min_2  \\\n",
      "265  0.053276  0.048753  0.322551  0.028014  0.071513  0.103117  0.213896   \n",
      "294  0.050268  0.045216  0.325980  0.022045  0.093635  0.098712  0.263232   \n",
      "93   0.039906  0.040224  0.299773  0.026325  0.037645  0.062903  0.138509   \n",
      "239  0.046191  0.034343  0.321700  0.011467  0.058744  0.060235  0.213817   \n",
      "380  0.755322  0.834896  0.718520  0.630766  0.595110  0.989157  0.372227   \n",
      "359  0.883303  0.952678  0.911085  0.758188  0.522456  0.966216  0.236021   \n",
      "0    0.000000  0.000000  0.260207  0.003868  0.061617  0.053061  0.254436   \n",
      "363  0.673161  0.991675  0.381705  0.790555  0.587747  0.843936  0.400487   \n",
      "20   0.028056  0.017221  0.311479  0.000452  0.074246  0.058301  0.296134   \n",
      "333  0.686934  0.969285  0.462673  0.856051  0.718725  0.995706  0.758325   \n",
      "\n",
      "        std_2     avg_3     max_3    ...       min_18    std_18    avg_21  \\\n",
      "265  0.069798  0.609063  0.635872    ...     0.335198  0.479961  0.445743   \n",
      "294  0.049618  0.588227  0.580174    ...     0.286323  0.394943  0.484576   \n",
      "93   0.051930  0.776656  0.964599    ...     0.007329  0.801333  0.686233   \n",
      "239  0.032836  0.696507  0.617901    ...     0.425130  0.511515  0.605958   \n",
      "380  0.840292  0.661246  0.670468    ...     0.353719  0.576388  0.428806   \n",
      "359  0.784948  0.525579  0.577118    ...     0.286355  0.384753  0.405277   \n",
      "0    0.008007  0.504157  0.410345    ...     0.529586  0.075397  0.008677   \n",
      "363  0.686495  0.544954  0.564258    ...     0.343451  0.532743  0.410474   \n",
      "20   0.001200  0.512703  0.390388    ...     0.587688  0.031917  0.000073   \n",
      "333  0.678165  0.727147  0.646944    ...     0.317814  0.500534  0.374621   \n",
      "\n",
      "       max_21    min_21    std_21    avg_22    max_22    min_22    std_22  \n",
      "265  0.612860  0.287503  0.235382  0.000738  0.000813  0.000061  0.000547  \n",
      "294  0.629802  0.265400  0.250547  0.000424  0.000831  0.000109  0.000518  \n",
      "93   0.877168  0.393161  0.312886  0.640930  0.957611  0.286114  0.810427  \n",
      "239  0.637971  0.571231  0.049701  0.000063  0.000081  0.000004  0.000076  \n",
      "380  0.630225  0.243744  0.230375  0.000728  0.000791  0.000016  0.000631  \n",
      "359  0.629578  0.217560  0.279899  0.000611  0.000818  0.000113  0.000760  \n",
      "0    0.008859  0.008307  0.000563  0.000716  0.005001  0.000000  0.003912  \n",
      "363  0.623041  0.217971  0.269720  0.000596  0.000759  0.000232  0.000617  \n",
      "20   0.000030  0.000103  0.000000  0.005776  0.004168  0.008521  0.000000  \n",
      "333  0.613176  0.227734  0.258177  0.000533  0.000722  0.000035  0.000749  \n",
      "\n",
      "[10 rows x 80 columns]\n",
      "kNN算法预测准确率为： 0.6705977775725674\n",
      "最后10个数据预测标签\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "Must fit neighbors before querying.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-961ec63cfb47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"kNN算法预测准确率为：\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"最后10个数据预测标签\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m     \u001b[0mlabelPredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabelPredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"最后10个数据真实标签\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \"\"\"\n\u001b[0;32m    326\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Must fit neighbors before querying.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: Must fit neighbors before querying."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "def importData():\n",
    "    data1 = pd.read_table('data1.txt', sep=',')\n",
    "    data2 = pd.read_table('data2.txt', sep=',')\n",
    "    # 数据收集完成后，发现GPS经纬度基本没有变化（大小变化约在8位以后），所以删除经纬度，\n",
    "    # 因收集样本有限，并且大部分人都在室内活动，情景模式基本都为震动，没有太大参考价值，删除情景模式\n",
    "    data1 = data1.drop('19', 1)\n",
    "    data1 = data1.drop('20', 1)\n",
    "    data1 = data1.drop('23', 1)\n",
    "    allData = data1.append(data2)\n",
    "    return allData\n",
    "\n",
    "\n",
    "def newFeaturesAndLabelsInit():\n",
    "    newFeatures = pd.DataFrame(\n",
    "        columns=['avg_1', 'max_1', 'min_1', 'std_1', 'avg_2', 'max_2', 'min_2', 'std_2', 'avg_3', 'max_3', 'min_3',\n",
    "                 'std_3',\n",
    "                 'avg_4', 'max_4', 'min_4', 'std_4', 'avg_5', 'max_5', 'min_5', 'std_5', 'avg_6', 'max_6', 'min_6',\n",
    "                 'std_6',\n",
    "                 'avg_7', 'max_7', 'min_7', 'std_7', 'avg_8', 'max_8', 'min_8', 'std_8', 'avg_9', 'max_9', 'min_9',\n",
    "                 'std_9',\n",
    "                 'avg_10', 'max_10', 'min_10', 'std_10', 'avg_11', 'max_11', 'min_11', 'std_11',\n",
    "                 'avg_12', 'max_12', 'min_12', 'std_12', 'avg_13', 'max_13', 'min_13', 'std_13',\n",
    "                 'avg_14', 'max_14', 'min_14', 'std_14', 'avg_15', 'max_15', 'min_15', 'std_15',\n",
    "                 'avg_16', 'max_16', 'min_16', 'std_16', 'avg_17', 'max_17', 'min_17', 'std_17',\n",
    "                 'avg_18', 'max_18', 'min_18', 'std_18', 'avg_21', 'max_21', 'min_21', 'std_21',\n",
    "                 'avg_22', 'max_22', 'min_22', 'std_22'])\n",
    "    newLabels = pd.DataFrame(columns=['labels'])\n",
    "    return newFeatures, newLabels\n",
    "\n",
    "\n",
    "def handleData(length, count):\n",
    "    list_avg = []\n",
    "    list_max = []\n",
    "    list_min = []\n",
    "    list_std = []\n",
    "    list_labels = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < (length - 10):\n",
    "        j = i + 10\n",
    "        data_slice = features.iloc[i:j, count]  # iloc函数传入的参数是位置索引\n",
    "        list_avg.append(data_slice.mean())\n",
    "        list_max.append(data_slice.max())\n",
    "        list_min.append(data_slice.min())\n",
    "        list_std.append(data_slice.std())\n",
    "        i = j\n",
    "    newFeatures['avg_' + str(count + 1)] = np.array(list_avg)\n",
    "    newFeatures['max_' + str(count + 1)] = np.array(list_max)\n",
    "    newFeatures['min_' + str(count + 1)] = np.array(list_min)\n",
    "    newFeatures['std_' + str(count + 1)] = np.array(list_std)\n",
    "    list_avg.clear()\n",
    "    list_max.clear()\n",
    "    list_min.clear()\n",
    "    list_std.clear()\n",
    "\n",
    "\n",
    "def handleData2():\n",
    "    list_avg = []\n",
    "    list_max = []\n",
    "    list_min = []\n",
    "    list_std = []\n",
    "    list_labels = []\n",
    "\n",
    "    handleData(features.shape[0], 0)\n",
    "    handleData(features.shape[0], 1)\n",
    "    handleData(features.shape[0], 2)\n",
    "    handleData(features.shape[0], 3)\n",
    "    handleData(features.shape[0], 4)\n",
    "    handleData(features.shape[0], 5)\n",
    "    handleData(features.shape[0], 6)\n",
    "    handleData(features.shape[0], 7)\n",
    "    handleData(features.shape[0], 8)\n",
    "    handleData(features.shape[0], 9)\n",
    "    handleData(features.shape[0], 10)\n",
    "    handleData(features.shape[0], 11)\n",
    "    handleData(features.shape[0], 12)\n",
    "    handleData(features.shape[0], 13)\n",
    "    handleData(features.shape[0], 14)\n",
    "    handleData(features.shape[0], 15)\n",
    "    handleData(features.shape[0], 16)\n",
    "    handleData(features.shape[0], 17)\n",
    "    # for count in range(17):\n",
    "    #     handleData(features.shape[0],count)\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < (features.shape[0] - 10):\n",
    "        j = i + 10\n",
    "        data_slice = features.iloc[i:j, 18]\n",
    "        list_avg.append(data_slice.mean())\n",
    "        list_max.append(data_slice.max())\n",
    "        list_min.append(data_slice.min())\n",
    "        list_std.append(data_slice.std())\n",
    "        i = j\n",
    "    newFeatures['avg_21'] = np.array(list_avg)\n",
    "    newFeatures['max_21'] = np.array(list_max)\n",
    "    newFeatures['min_21'] = np.array(list_min)\n",
    "    newFeatures['std_21'] = np.array(list_std)\n",
    "    list_avg.clear()\n",
    "    list_max.clear()\n",
    "    list_min.clear()\n",
    "    list_std.clear()\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < (features.shape[0] - 10):\n",
    "        j = i + 10\n",
    "        data_slice = features.iloc[i:j, 19]\n",
    "        list_avg.append(data_slice.mean())\n",
    "        list_max.append(data_slice.max())\n",
    "        list_min.append(data_slice.min())\n",
    "        list_std.append(data_slice.std())\n",
    "        list_labels.append(allData.iloc[i, -1])  # 选取allData里面第i行，最后一列作为labels\n",
    "        i = j\n",
    "    newFeatures['avg_22'] = np.array(list_avg)\n",
    "    newFeatures['max_22'] = np.array(list_max)\n",
    "    newFeatures['min_22'] = np.array(list_min)\n",
    "    newFeatures['std_22'] = np.array(list_std)\n",
    "    newLabels['labels'] = np.array(list_labels)\n",
    "    list_avg.clear()\n",
    "    list_max.clear()\n",
    "    list_min.clear()\n",
    "    list_std.clear()\n",
    "    list_labels.clear()\n",
    "    return newFeatures, newLabels\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 数据导入\n",
    "    allData = importData()\n",
    "\n",
    "    # 数据预处理\n",
    "    # 清理整行属性都为空的行\n",
    "    allData.dropna(how=\"all\")\n",
    "    # 本来打算填充众数，因为无缺失值，后改为删除含有空属性的行，结果不变\n",
    "    allData.dropna(axis=0)\n",
    "    # 剩余部分缺失值也可以采用出现最频繁的值填充\n",
    "    # freq_port = allData.Embarked.dropna().mode()[0] # mode返回出现最多的数据，可能出现多个，因此返回数组,取第0个\n",
    "    # dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n",
    "\n",
    "    # 输出数据形状\n",
    "    allData_row = allData.shape[0]\n",
    "    allDate_col = allData.shape[1]\n",
    "    print(\"原始数据规模：\", allData.shape[0], \" * \", allData.shape[1]+2)\n",
    "    print(\"删除GPS属性后，数据规模：\", allData.shape[0], \" * \", allData.shape[1])\n",
    "\n",
    "    # 选取所有行，和最后一列之前的所有列，后面的“：-1”表示左闭右开\n",
    "    features = allData.iloc[:, :-1]\n",
    "    print(\"特征数目：\", features.shape[1])\n",
    "\n",
    "    # 特征提取\n",
    "    # 以每10组数据为一组提取获得的20个属性的平均值，最大值，最小值，标准差，作为新的特征向量\n",
    "    newFeatures, newLabels = newFeaturesAndLabelsInit()\n",
    "    newFeatures, newLabels = handleData2()\n",
    "\n",
    "    # 输出提取特征后，新的特征维度个数\n",
    "    newFeatures_row = newFeatures.shape[1]\n",
    "    print(\"特征提取后，特征数目：\", newFeatures_row)\n",
    "    print()\n",
    "\n",
    "    # 归一化处理\n",
    "    normal_data = (newFeatures - newFeatures.min()) / (newFeatures.max() - newFeatures.min())\n",
    "\n",
    "    # 特征和标签分别赋值\n",
    "    X = normal_data\n",
    "    y = newLabels['labels']\n",
    "    # 划分训练集和预测集\n",
    "    # 设置stratify = y时，我们发现每次划分后，测试集和训练集中的类标签比例同原始的样本中类标签的比例相同\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "    \n",
    "    # PCA降维过程\n",
    "    pca = PCA(n_components = 'mle',copy = False).fit(X_train)\n",
    "    X_train_pca = pca.transform(X)\n",
    "#     X_test_pca = pca.transform(X_test)\n",
    "    # 输出降维后的结果\n",
    "    print(X_train_pca.shape)\n",
    "    print(\"各成分占总方差比例：\")\n",
    "    print(pca.explained_variance_ratio_ )\n",
    "    print(\"各成分方差：\")\n",
    "    print(pca.explained_variance_ )\n",
    "\n",
    "    # 进行预测\n",
    "    print(\"最后十个数据为：\")\n",
    "    print(X_test.tail(10))\n",
    "    \n",
    "    # kNN\n",
    "    t0 = time.time()\n",
    "    clf = KNeighborsClassifier(n_neighbors=16, algorithm='auto', weights='distance')\n",
    "    clf.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    print(\"kNN算法预测准确率为：\", cross_val_score(clf,X, y,cv=10).mean())\n",
    "    print(\"最后10个数据预测标签\")\n",
    "    labelPredict = clf.predict(X_test.tail(10))\n",
    "    print(labelPredict)\n",
    "    print(\"最后10个数据真实标签\")\n",
    "    labelData = y_test.tail(10)\n",
    "    print(labelData)\n",
    "    print(\"耗时%0.3fs\\n\" % (t1 - t0))\n",
    "    # 绘制图像显示不同K值对应的预测准确率\n",
    "    k_range = range(1, 31)\n",
    "    k_scores = []\n",
    "    for k in k_range:\n",
    "        clf = KNeighborsClassifier(n_neighbors=k)\n",
    "        # loss = -cross_val_score(clf, X, y, cv=10, scoring='mean_squared_error') # for regression\n",
    "        # 当cv参数是一个整型时，cross_val_score默认使用KFold 或StratifiedKFold的方法进行数据集打乱\n",
    "        scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')  # for classification\n",
    "        k_scores.append(scores.mean())\n",
    "    plt.plot(k_range, k_scores)\n",
    "    plt.xlabel('Value of K for KNN')\n",
    "    plt.ylabel('Cross-Validated Accuracy')\n",
    "    plt.show()\n",
    "\n",
    "    # SVC(kernel='linear')\n",
    "    t0 = time.time()\n",
    "    clf = svm.SVC(kernel='linear',decision_function_shape='ovo')\n",
    "#     clf.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    print(\"SVC算法(kernel='linear')预测准确率为：\", cross_val_score(clf,X, y,cv=10).mean())\n",
    "    print(\"最后10个数据预测标签\")\n",
    "    labelPredict = clf.predict(X_test.tail(10))\n",
    "    print(labelPredict)\n",
    "    print(\"最后10个数据真实标签\")\n",
    "    labelData = y_test.tail(10)\n",
    "    print(labelData)\n",
    "    print(\"耗时%0.3fs\\n\" % (t1 - t0))\n",
    "\n",
    "    # SVC(kernel='poly')\n",
    "    t0 = time.time()\n",
    "    clf = svm.SVC(kernel='poly',decision_function_shape='ovo')\n",
    "#     clf.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    print(\"SVC算法(kernel='poly')预测准确率为：\", cross_val_score(clf,X, y,cv=10).mean())\n",
    "    print(\"最后10个数据预测标签\")\n",
    "    labelPredict = clf.predict(X_test.tail(10))\n",
    "    print(labelPredict)\n",
    "    print(\"最后10个数据真实标签\")\n",
    "    labelData = y_test.tail(10)\n",
    "    print(labelData)\n",
    "    print(\"耗时%0.3fs\\n\" % (t1 - t0))\n",
    "\n",
    "    # SVC(kernel='rbf')\n",
    "    t0 = time.time()\n",
    "    clf = svm.SVC(kernel='rbf',decision_function_shape='ovo')\n",
    "#     clf.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    print(\"SVC算法(kernel='rbf')预测准确率为：\", cross_val_score(clf,X, y,cv=10).mean())\n",
    "    print(\"最后10个数据预测标签\")\n",
    "    labelPredict = clf.predict(X_test.tail(10))\n",
    "    print(labelPredict)\n",
    "    print(\"最后10个数据真实标签\")\n",
    "    labelData = y_test.tail(10)\n",
    "    print(labelData)\n",
    "    print(\"耗时%0.3fs\\n\" % (t1 - t0))\n",
    "\n",
    "    # 高斯朴素贝叶斯\n",
    "    t0 = time.time()\n",
    "    clf = GaussianNB()\n",
    "#     clf.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    print(\"高斯朴素贝叶斯算法预测准确率为：\", cross_val_score(clf,X, y,cv=10).mean())\n",
    "    print(\"最后10个数据预测标签\")\n",
    "    labelPredict = clf.predict(X_test.tail(10))\n",
    "    print(labelPredict)\n",
    "    print(\"最后10个数据真实标签\")\n",
    "    labelData = y_test.tail(10)\n",
    "    print(labelData)\n",
    "    print(\"耗时%0.3fs\\n\" % (t1 - t0))\n",
    "\n",
    "    # 多项式分布\n",
    "    t0 = time.time()\n",
    "#     clf = MultinomialNB().fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    print(\"多项式分布朴素贝叶斯算法预测准确率为：\", cross_val_score(clf,X, y,cv=10).mean())\n",
    "    print(\"最后10个数据预测标签\")\n",
    "    labelPredict = clf.predict(X_test.tail(10))\n",
    "    print(labelPredict)\n",
    "    print(\"最后10个数据真实标签\")\n",
    "    labelData = y_test.tail(10)\n",
    "    print(labelData)\n",
    "    print(\"耗时%0.3fs\\n\" % (t1 - t0))\n",
    "\n",
    "    # 伯努利分布\n",
    "    t0 = time.time()\n",
    "    clf = BernoulliNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    print(\"伯努利分布贝叶斯算法预测准确率为：\", cross_val_score(clf,X, y,cv=10).mean())\n",
    "    print(\"最后10个数据预测标签\")\n",
    "    labelPredict = clf.predict(X_test.tail(10))\n",
    "    print(labelPredict)\n",
    "    print(\"最后10个数据真实标签\")\n",
    "    labelData = y_test.tail(10)\n",
    "    print(labelData)\n",
    "    print(\"耗时%0.3fs\\n\" % (t1 - t0))\n",
    "    \n",
    "#     # Adaboost算法\n",
    "#     time_1 = time.time()\n",
    "#     print('Start training...') \n",
    "#     # n_estimators表示要组合的弱分类器个数；\n",
    "#     # algorithm可选{‘SAMME’, ‘SAMME.R’}，默认为‘SAMME.R’，表示使用的是real boosting算法，‘SAMME’表示使用的是discrete boosting算法\n",
    "#     clf = AdaBoostClassifier(n_estimators=100,algorithm='SAMME.R',learning_rate=0.1)\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     time_2 = time.time()\n",
    "#     print('training cost %f seconds' % (time_2 - time_1))\n",
    "    \n",
    "#     scores = cross_val_score(clf,X_test,y_test)\n",
    "\n",
    "#     print('Start predicting...')\n",
    "#     test_predict = clf.predict(X_test)\n",
    "#     time_3 = time.time()\n",
    "#     print('predicting cost %f seconds' % (time_3 - time_2))\n",
    "\n",
    "#     score = accuracy_score(y_test, test_predict)\n",
    "#     print(\"The accruacy score is %f\" % score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
